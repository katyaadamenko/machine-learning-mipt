{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'https://kaggle2.blob.core.windows.net/competitions-data/inclass/6441/linear_train.txt?sv=2015-12-11&sr=b&sig=fTqXqYzEK3FTZ9U8Du7Hxamitpga7%2BZsuQnbm6tFFUw%3D&se=2017-04-12T15%3A51%3A59Z&sp=r'\n",
    "test_path = 'https://kaggle2.blob.core.windows.net/competitions-data/inclass/6441/linear_test.txt?sv=2015-12-11&sr=b&sig=PCxO95%2Batezu0YUs%2FW97ebebbkJCJQL5UuP80YzPh6Q%3D&se=2017-04-12T15%3A53%3A53Z&sp=r'\n",
    "train = pd.read_csv(train_path, names=[\"word\", \"target\"])\n",
    "test = pd.read_csv(test_path, names=[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programs\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\programs\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54797772  0.34331718  0.246279    0.75904001  0.75530851]\n",
      "0.530384485591\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(min_df=5, ngram_range=(2, 5), analyzer='char_wb', lowercase=False, binary=True), \n",
    "                         LogisticRegression(penalty='l1', C=0.7))\n",
    "arr = cross_val_score(pipeline, train.word, train.target, cv=5, scoring='roc_auc')\n",
    "print arr\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='char_wb', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(2, 5), preprocessor=None, stop_words=Non...ty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train.word, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78598900348365863"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train.target, pipeline.predict(train.word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим результат на кросс валидации для разных моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57778435  0.41324666  0.34933166  0.78071966  0.71910147]\n",
      "0.56803676085\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(min_df=5, ngram_range=(2, 5), analyzer='char_wb', lowercase=False, binary=True), \n",
    "                         SGDClassifier())\n",
    "arr = cross_val_score(pipeline, train.word, train.target, cv=5, scoring='roc_auc')\n",
    "print arr\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(train.target, n_iter=5, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90835669  0.91436489  0.91435337  0.91231753  0.91134158]\n",
      "0.912146810889\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(min_df=5, ngram_range=(1, 4), analyzer='char_wb', lowercase=False), \n",
    "                         LogisticRegression(penalty='l1', C=1))\n",
    "arr = cross_val_score(pipeline, train.word, train.target, cv=cv, scoring='roc_auc')\n",
    "print arr\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countvectorizer__encoding',\n",
       " 'logisticregression__n_jobs',\n",
       " 'countvectorizer__decode_error',\n",
       " 'logisticregression__dual',\n",
       " 'countvectorizer__input',\n",
       " 'logisticregression__warm_start',\n",
       " 'countvectorizer__stop_words',\n",
       " 'countvectorizer__tokenizer',\n",
       " 'logisticregression__multi_class',\n",
       " 'logisticregression',\n",
       " 'logisticregression__random_state',\n",
       " 'logisticregression__verbose',\n",
       " 'countvectorizer__lowercase',\n",
       " 'countvectorizer__min_df',\n",
       " 'countvectorizer__strip_accents',\n",
       " 'logisticregression__class_weight',\n",
       " 'countvectorizer__preprocessor',\n",
       " 'logisticregression__intercept_scaling',\n",
       " 'countvectorizer__binary',\n",
       " 'countvectorizer__token_pattern',\n",
       " 'countvectorizer__max_df',\n",
       " 'logisticregression__max_iter',\n",
       " 'countvectorizer__max_features',\n",
       " 'countvectorizer__ngram_range',\n",
       " 'logisticregression__solver',\n",
       " 'logisticregression__fit_intercept',\n",
       " 'countvectorizer__analyzer',\n",
       " 'countvectorizer',\n",
       " 'logisticregression__penalty',\n",
       " 'logisticregression__C',\n",
       " 'steps',\n",
       " 'countvectorizer__vocabulary',\n",
       " 'countvectorizer__dtype',\n",
       " 'logisticregression__tol']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём параметры count_vectorizer с помощью grid search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'logisticregression__C':[0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 1], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'countvectorizer__min_df':[1, 2, 3, 4, 5],\n",
    "              'countvectorizer__ngram_range':[(2, 4), (2, 5), (1, 3), (2, 3), (1, 4), (1, 5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=1, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(train.word[:3000], train.target[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countvectorizer__min_df: 1\n",
      "countvectorizer__ngram_range: (2, 5)\n"
     ]
    }
   ],
   "source": [
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91675139  0.91849583  0.91380319  0.91597399  0.91955182]\n",
      "0.916915243104\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(min_df=2, ngram_range=(2, 5), analyzer='char_wb', lowercase=False, binary=False), \n",
    "                         LogisticRegression(penalty='l1', C=1.0))\n",
    "arr = cross_val_score(pipeline, train.word, train.target, cv=cv, scoring='roc_auc')\n",
    "print arr\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='char_wb', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(2, 5), preprocessor=None, stop_words=No...ty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train.word, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36121852,  0.19138054,  0.20404121, ...,  0.08519476,\n",
       "        0.00899449,  0.01748734])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(train.word)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97172093612495769"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train.target, pipeline.predict_proba(train.word)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39627602,  0.21694818,  0.18684353, ...,  0.02677278,\n",
       "        0.00086459,  0.0006587 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(test.word)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.396276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.216948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.186844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.100816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.204041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Answer\n",
       "0   0  0.396276\n",
       "1   1  0.216948\n",
       "2   2  0.186844\n",
       "3   3  0.100816\n",
       "4   4  0.204041"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pipeline.predict_proba(test.word)[:, 1]\n",
    "submit = pd.DataFrame()\n",
    "submit['Id'] = xrange(len(test))\n",
    "submit['Answer'] = pred\n",
    "submit.to_csv('submit.csv', index=None)\n",
    "submit[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.83111882725974007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
